{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aalto Pro/Diploma in Artificial Intelligence: Project work\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying data science and machine learning in development of a tool for sustainable waste management onboard cruise ship\n",
    "\n",
    "### Abstract\n",
    "\n",
    "\n",
    "### Background\n",
    "\n",
    "In this work, a data product will be produced by using data science tools and machine learning (ML) algorithms that would help a cruise ship operator to plan ahead the future waste management operations by a most sustainable and feasible way.\n",
    "The project work is done by constructing the ML-product by using real shipboard operational data and external web sources. The purpose is to create ML-system that would give a decent picture and prediction of the best option for the operations.\n",
    "\n",
    "#### Cruise ship waste\n",
    "\n",
    "A cruise ship is a passenger ship used for pleasure voyages when the voyage itself, the ship's amenities, and sometimes the different destinations along the way (i.e., ports of call), form part of the passengers' experience [1]. Modern cruise ships can be considered as a combination of hotel, shopping center, amusement park, casino, spa and a center of all kind of restaurants with big galleys for preparation of all kind of meals. All these onboard activities produces high volumes of wastes that is around 2 to 3 times the amount produced by municipal centers per capita [2]. Especially, as all the meals (around 8 per each day) are prepared onboard the ship in the central galleys. Thereby, organic and nutrient loading of the waste, if discharged to the sea, is very high.\n",
    "\n",
    "The waste management system of a modern cruise ship is confined to ship machinery spaces. There are basically three type of solid waste produced onboard: Dry waste (DW), food waste (FW) and biosludge waste(BW). The DW is mainly solid packing materials from the provisions and unsorted waste from the cabins and restaurants. The FW is produced mainly from the food preparation from the gallies but also as a food rejects from bars, restaurants and crew messes of the ship. The BW is a biological surplus sludge from the ship wastewater treatment plant.\n",
    "\n",
    "The management and the discharge of the waste materials is strictly regulated by both international and national legislations and guidelines. International Maritime Organisation (IMO) [3] The discharge of garbage is strictly prohibited in all sea areas. The discharge of FW and BW is also strictly regulated and also prohibited in many special sea areas. In addition to this the storage silos for these waste materials is very limited and is sufficient only for couple of days.\n",
    "\n",
    "#### Motivation for the work\n",
    "\n",
    "Evac Oy supplies integrated cleantech solutions, including e.g. waste management systems, to all types of ships. The cruise ships are our biggest market segment and for past few years Evac has had more than 80 % of market share in waste systems. The sustainability is the key value for all major cruise ship owners. Not only because of regulations and guidelines, but because of acceptability of the cruise business as a whole. Basically, the cruise ships are operated by zero-discharge principle.\n",
    "\n",
    "The cruise ships are operated on a strictly defined itinerary and and in the given schedule. The shipboard waste management is not the main operation of the ship and should by not means affect the operation of a ship. On the other hand, volumetric production of the waste streams (DW, FW, BW) are not constant and are fairly unpredictable. As mentioned the onboard storage silos are very small in volume. For that reason, cruise ships are many times forced to store waste container in corridors and luggage storages. For the same reason, ships are frequently discharging high proportion of untreated FW and BW directly into the sea. This poses high risk for the reputation of the ship owners as well as for the whole cruise business.\n",
    "\n",
    "### Purpose and objective\n",
    "\n",
    "The purpose of this work is to carry out an exploratory analysis on the waste data produced from one of the ships of TUI Cruises to produce an insight of the dynamics of the waste production. From that knowledge a machine learning tool is trained and validated to predict the production of the waste streams. Ultimately, the project should produce a machine learning tool that will predict the production of the three streams and thereby help the operator to plan ahead the waste management operations of the ship.\n",
    "\n",
    "The goal is to study how to extract usable data from the existing sources, clean and explore the data so that a usable predictive ML models could be produced and trained with new and fresh data in the future from the IoT-system. When this goal is achieved, it may be worth of considering to apply and further develop the extent of the work to an usable data science product.\n",
    "\n",
    "\n",
    "## Materials and methods\n",
    "\n",
    "\n",
    "### Data sources\n",
    "\n",
    "#### Shipboard data\n",
    "\n",
    "There are both internal and external data sources that would be used. The internal data sources are the waste data produced from the ship IoT. In the first stage of data exploration, a set of readily produced CSV-files containing all the waste data from Mein Schiff 6 covering couple of days. The raw data set consists of:\n",
    "\n",
    "- volume as cubic meters (m3) of dry waste produced onboard cruise ship into a dry waste silo. The CSV file contains status information of the gate valves that needs to be converted into a volumetric values of waste production. This data is converted to kilograms (kg) of dry waste and eventually rate of production.\n",
    "\n",
    "- volume as cubic meters (m3) of food waste produced continuously onboard cruise ship into a food waste silo. There are two FW silos. The data is produced as filling %-level of the tanks. The data is converted into cumulative production of kilograms (kg) of food waste and eventually as rate of production\n",
    "\n",
    "- volume as cubic meters (m3) of biosludge produced continuously onboard cruise ship into a BW silo. The data is produced as filling %-level of the tanks. The data is converted into cumulative production of kilograms (kg) of BW and eventually as rate of production.\n",
    "\n",
    "In addition to the waste data, there is data of the waste management system including pumping information of the FW solids and liquid and data from waste incinerator units.\n",
    "\n",
    "The first set of data is produced from Mein Schiff 6. As said, the data of the waste production is first cleaned and plotted to understand the nature of the data. These data sets will be used as labeled data for prediction of future waste production trends. The first development and training of the ML-model is done with this data set.\n",
    "\n",
    "\n",
    "#### Operational data\n",
    "\n",
    "For predicting the future waste production, we need to understand the basic facts and activities affecting the waste production rate in order to select sensible and most influential features for our ML-model. First one need to ask that is the ML-model really needed to know the future waste production. Basically, the prediction model would not be needed if the the production rate is either constant or the pattern of production rate is well known.\n",
    "\n",
    "Is the production rate constant and/or is the production pattern know? To answer that question one need to know the variables affecting the waste production. The pattern of production is dependant mainly on:\n",
    "\n",
    "- Activity of passangers that is dependant on the time of a day: That would basically be solved with Pandas datetime-data type.\n",
    "\n",
    "- Amount of passangers onboard: Basically, it is safe to assume that the ship is always fully booked, that is the situation almost always for all cruise ships in real life. This may be thereby either neglected or use constant integer, i.e. known capacity of the ship derived from the web site of the ship by web scraping.\n",
    "\n",
    "- Proportion of passangers present onboard: Cruise ships visit the ports on a daily basis and most of the cruise ship customers disembark to the port of call. So, the relevant question affecting the waste production; is the ship in a port side or cruising in the sea conditions? This information can be derived from the web site of the ship by web scraping. The data type is boolean.\n",
    "\n",
    "- The amount of food waste is dependant on the meal time, meaning that two hours before and until the meal time the main galleys are fully operational. We can assume the meal times of a day based on our knowledge about the ship operation. The data type is boolean.\n",
    "\n",
    "- During staying in the turnaround port (i.e. home port). The waste production is higher because the whole ship is cleaned between 8:00 am and 01:00 pm. This increases substantially the amount of DW.This information can be derived from the web site of the ship by web scraping. The data type is boolean.\n",
    "\n",
    "As we can see, there is at least five most relevant attributes affecting the waste production rates. Thereby, one can safely conclude that the production rates aren't constant nor known. We can also conclude that the rates are not same throughout one day. Most likely the the production patterns are very ship-specific and cannot be generalised from single attribute. Therefore, the development of the predictive machine learning model is a relevant task.\n",
    "\n",
    "\n",
    "### Method for development of Predictive Machine Learning model\n",
    "\n",
    "\n",
    "Typical situation for creating a predictive model is that in a set of inputs (X) are readily available, but the output (Y) cannot be easily obtained [4]. The output can be predicted with an estimate of function describing the unknown relationship between X and Y. Basically, a model, that is an estimate of the relationship, is at first treated as a black box that would be called as hypothesis space, meaning all computationally reasonable relationships between X and Y.\n",
    "\n",
    "\n",
    "#### Definition of the setup for the machine learning task\n",
    "\n",
    "\n",
    "In this project, the high-level insight produced by the model is the production of the waste streams, DW, FW and BW, that will tell whether or not the storage capacities are sufficient. This will return recommendation of actions whether to treat the waste onboard, store in the silos or if the waste needs to be discharged to the sea. As an ultimate goal would be to combine the return value of sustainability in terms of environmental impact or feasibility information in terms of cash flow or cost from waste disposal.\n",
    "\n",
    "The inputs (X) as relevant features for the ML-model are the operational data described above. The labelled data as relevant higher-level insights are the known shipboard data described above. This data will be supplemented by additional data from the IoT-system onboard Mein Schiff 2, that will be live after 11th April 2019. This data will be also used for furter training of the model as well as for the validation of the model.\n",
    "\n",
    "The output (Y) predictions will be the predicted waste productions.\n",
    "\n",
    "\n",
    "#### Development of the ML-model\n",
    "\n",
    "\n",
    "The relevant question for development of the model is that is it possible to predict the waste production from the operational data listed above. The main prerequisite for development and training of predictive regression model is a feature space that is quantitative. However, as we can see our given feature space contains mainly categorical features with a boolean values.\n",
    "\n",
    "In this case, one proven technique is to use one-hot encoding, which effectively creates extra columns indicating the presence or absence of a category with a value of 1 or 0, respectively [5]. In this project that would simply mean, e.g. ships location is indicated as one category a sea condition as 1 (True) and portside as 0 (False). Also, the meal time is one category indicated as either 1 (True) and rest of the time as 0 (False).\n",
    "\n",
    "After preprosessing the features into useable feature space, the model is developed. The labelled data is joined with the another dataset. Basically, try to determine the extent to which the above listed operational data affect the volume of waste streams. A simple linear regression is performed to relate the operations and the labeled data.\n",
    "\n",
    "The linear regression functionality of the Scikit-Learn-package will be utilised for model development and training the model as well as for the validation of the model\n",
    "\n",
    "\n",
    "### Computational infrastructure, software product considerations\n",
    "\n",
    "The work is done with Jupyter Lab of Anaconda distribution package. The code will be written in Python meaning that all the usable Python libraries, incl. Pandas for data preparation, Matplotlib and Seaborn for visualisation of cleaned data and Scikit-Learn for model training and validation.\n",
    "\n",
    "The model development is the main goal of the project. As I have only basic level of programming knowledge, there is no guarantees that the work will be finalized as data product to be utilised by end-customer. The primary goal of the work is to learn the methods of data science and machine learning. If I get to the production stage with this work, the GUI would be developed PyQt-GUI-tool. Alternatively, a web application could be developed with Python Flask-package. As there is lot of real time data available, it would be preferable to have it running real time. For the employer company point of view, a software product would be the desired option. However, most of the efforts during these studies should be put to data management and the ML-model building. As long as there is no connection between a specific ship or the ship owner, there should not be any privacy issues. The model should basically be a tool for evaluating sustainability of human actions towards the nature. \n",
    "\n",
    "\n",
    "## Preliminary Conclusions \n",
    "\n",
    "Preliminary, it can be concluded that the data from the ship IoT-system is both dense and thereby noisy. The data sampling interval on 3 to 5 seconds is emphasising the underlying noise caused mainly by ship movement. Also, the data is derived mainly only as status information that causes multi-stage data transformation before one can make any meaningful visualisation of the data.\n",
    "\n",
    "Deriving the operational data by web scraping is a good rehearsal for practice of data hacking from the website. However, the reliability of the data is dependant on whether or not the data on the webpage is correct or not. This entails a risk for model development stage.\n",
    "\n",
    "The feature space contains mainly categorical data and needs preprocessing prior to model development. Also, it remains to be seen if this categorical feature space is applicable for training a reliable model.\n",
    "\n",
    "\n",
    "##  References:\n",
    "\n",
    "[1] https://en.wikipedia.org/wiki/Cruise_ship\n",
    "\n",
    "[2] Cruise ship waste management database. Evac Oy. 2019.\n",
    "\n",
    "[3] IMO Marpol Annex V, Resolution MEPC. 295(71).\n",
    "    http://www.imo.org/en/OurWork/Environment/PollutionPrevention/Garbage/Pages/Default.aspx\n",
    "\n",
    "[4] An Introduction to Statistical Learning with Applications in R. Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. 2017. eBook. Corrected at 8th printing.\n",
    "\n",
    "[5] Python Data Science Handbook. Essential Tools For Working With Data. Jake VanderPlas. 2017. 1st Edition. O'Reilly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX 1: Code of the project. Status 1st of April 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(filename):# FILENAME ON INPUT-PARAMETRINÄ LOADDATA-FUNKTIOLLE. FILENAME ANNETAAN SIIS FUNKTIOTA KÄYTETTÄESSÄ.\n",
    "    \"\"\"\n",
    "    Load the csv reading the file with the filename given as a parameter.\n",
    "    Print the sample size m and the feature length n.\n",
    "\n",
    "    :input: String path to the file\n",
    "\n",
    "    :return: pandas dataframe of shape=(m, n, ty), the sample size m and the feature length n \n",
    "    and the data type ty. In this case no conversion to Numpy array    \n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename, delimiter=';')\n",
    "    #X = df.values # convert the data frame to numpy array\n",
    "    n = df.shape[1]        # second element of \"dimension\" is the number of cols\n",
    "    m = df.shape[0]        # first element of dimension is the number of rows\n",
    "    ty = type(df)\n",
    "    print('sample size m=',m)\n",
    "    print('feature length n=',n)\n",
    "    print('the data type is', ty)\n",
    "    return df, m, n, ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size m= 402860\n",
      "feature length n= 5\n",
      "the data type is <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "FWAsource, m, n, ty, = LoadData('MS6/LEVEL_TANK_A0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VarName</th>\n",
       "      <th>TimeString</th>\n",
       "      <th>VarValue</th>\n",
       "      <th>Validity</th>\n",
       "      <th>Time_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODWASTE_TANK_A_LEVEL_TREND</td>\n",
       "      <td>25.02.2018 16:07:23</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>43156671788,5185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HARSLEV_PUMP_1_1PM_1_STATUS</td>\n",
       "      <td>25.02.2018 16:07:25</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>43156671811,9097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THREEWAY_VALVE_1_1PV4_STATUS</td>\n",
       "      <td>25.02.2018 16:07:25</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>43156671811,9097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARSLEV_PUMP_1_1PM_1_STATUS</td>\n",
       "      <td>25.02.2018 16:07:27</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>43156671835,2894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THREEWAY_VALVE_1_1PV4_STATUS</td>\n",
       "      <td>25.02.2018 16:07:27</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>43156671835,2894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        VarName           TimeString  VarValue  Validity  \\\n",
       "0  FOODWASTE_TANK_A_LEVEL_TREND  25.02.2018 16:07:23        47         1   \n",
       "1   HARSLEV_PUMP_1_1PM_1_STATUS  25.02.2018 16:07:25        20         1   \n",
       "2  THREEWAY_VALVE_1_1PV4_STATUS  25.02.2018 16:07:25         5         1   \n",
       "3   HARSLEV_PUMP_1_1PM_1_STATUS  25.02.2018 16:07:27        20         1   \n",
       "4  THREEWAY_VALVE_1_1PV4_STATUS  25.02.2018 16:07:27         5         1   \n",
       "\n",
       "            Time_ms  \n",
       "0  43156671788,5185  \n",
       "1  43156671811,9097  \n",
       "2  43156671811,9097  \n",
       "3  43156671835,2894  \n",
       "4  43156671835,2894  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FWAsource.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDatac(filename):\n",
    "    \"\"\"\n",
    "    Load the csv reading the file with the filename given as a parameter.\n",
    "    Print the sample size m and the feature length n.\n",
    "\n",
    "    :input: String path to the file\n",
    "\n",
    "    :return: pandas dataframe of shape=(m, n, ty), the sample size m and the feature length n \n",
    "    and the data type ty. In this case no conversion to Numpy array    \n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename, delimiter=',')\n",
    "    #X = df.values # convert the data frame to numpy array\n",
    "    n = df.shape[1]        # second element of \"dimension\" is the number of cols\n",
    "    m = df.shape[0]        # first element of dimension is the number of rows\n",
    "    ty = type(df)\n",
    "    print('sample size m=',m)\n",
    "    print('feature length n=',n)\n",
    "    print('the data type is', ty)\n",
    "    return df, m, n, ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size m= 402860\n",
      "feature length n= 5\n",
      "the data type is <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "FWBsource, m, n, ty, = LoadData('MS6/LEVEL_TANK_B0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size m= 400952\n",
      "feature length n= 5\n",
      "the data type is <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "BWsource, m, n, ty, = LoadData('MS6/LEVEL_BIOSLUDGETANK0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size m= 500000\n",
      "feature length n= 5\n",
      "the data type is <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "DWsource, m, n, ty, = LoadData('MS6/Inc_1_datalog_functions0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VarName</th>\n",
       "      <th>TimeString</th>\n",
       "      <th>VarValue</th>\n",
       "      <th>Validity</th>\n",
       "      <th>Time_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inc_1_primary_burner_status</td>\n",
       "      <td>17.02.2018 21:03:15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877259,4097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inc_1_secondary_burner_status</td>\n",
       "      <td>17.02.2018 21:03:15</td>\n",
       "      <td>-20</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877259,4097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>17.02.2018 21:03:15</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877259,4097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inc_1_medical_flap_status</td>\n",
       "      <td>17.02.2018 21:03:15</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877259,4097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inc_1_primary_burner_status</td>\n",
       "      <td>17.02.2018 21:03:16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877271,0995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           VarName           TimeString  VarValue  Validity  \\\n",
       "0      inc_1_primary_burner_status  17.02.2018 21:03:15         0         1   \n",
       "1    inc_1_secondary_burner_status  17.02.2018 21:03:15       -20         1   \n",
       "2  inc_1_lower_feeding_gate_status  17.02.2018 21:03:15       -10         1   \n",
       "3        inc_1_medical_flap_status  17.02.2018 21:03:15        -5         1   \n",
       "4      inc_1_primary_burner_status  17.02.2018 21:03:16         0         1   \n",
       "\n",
       "            Time_ms  \n",
       "0  43148877259,4097  \n",
       "1  43148877259,4097  \n",
       "2  43148877259,4097  \n",
       "3  43148877259,4097  \n",
       "4  43148877271,0995  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DWsource.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Datetime(df):# PANDAS DF ON INPUT-PARAMETRINÄ FUNKTIOLLE. DF:N NIMI ANNETAAN SIIS FUNKTIOTA KÄYTETTÄESSÄ.\n",
    "    \"\"\"\n",
    "    Converts the str-type TimeString into more useful Pandas DateTime form.\n",
    "    \n",
    "    Prints the head of the DataFrame after conversion and the data type of the DateTime column.\n",
    "\n",
    "    :input: Name of the dataframe and the TimeString column of the DF in question.\n",
    "\n",
    "    :return: pandas dataframe with the DateTime and its data type.    \n",
    "    \"\"\"\n",
    "\n",
    "    df['DateTime'] = pd.to_datetime(df.TimeString, format = '%d.%m.%Y %H:%M:%S')\n",
    "    dty = type(df.DateTime)    # Returns datatype\n",
    "    print(df.head())\n",
    "    print('The time data type is now: ',dty)\n",
    "    return df, dty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           VarName           TimeString  VarValue  Validity  \\\n",
      "0      inc_1_primary_burner_status  17.02.2018 21:03:15         0         1   \n",
      "1    inc_1_secondary_burner_status  17.02.2018 21:03:15       -20         1   \n",
      "2  inc_1_lower_feeding_gate_status  17.02.2018 21:03:15       -10         1   \n",
      "3        inc_1_medical_flap_status  17.02.2018 21:03:15        -5         1   \n",
      "4      inc_1_primary_burner_status  17.02.2018 21:03:16         0         1   \n",
      "\n",
      "            Time_ms            DateTime  \n",
      "0  43148877259,4097 2018-02-17 21:03:15  \n",
      "1  43148877259,4097 2018-02-17 21:03:15  \n",
      "2  43148877259,4097 2018-02-17 21:03:15  \n",
      "3  43148877259,4097 2018-02-17 21:03:15  \n",
      "4  43148877271,0995 2018-02-17 21:03:16  \n",
      "The time data type is now:  <class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                VarName           TimeString  VarValue  \\\n",
       " 0           inc_1_primary_burner_status  17.02.2018 21:03:15         0   \n",
       " 1         inc_1_secondary_burner_status  17.02.2018 21:03:15       -20   \n",
       " 2       inc_1_lower_feeding_gate_status  17.02.2018 21:03:15       -10   \n",
       " 3             inc_1_medical_flap_status  17.02.2018 21:03:15        -5   \n",
       " 4           inc_1_primary_burner_status  17.02.2018 21:03:16         0   \n",
       " 5         inc_1_secondary_burner_status  17.02.2018 21:03:16       -20   \n",
       " 6       inc_1_lower_feeding_gate_status  17.02.2018 21:03:16       -10   \n",
       " 7             inc_1_medical_flap_status  17.02.2018 21:03:16        -5   \n",
       " 8           inc_1_primary_burner_status  17.02.2018 21:03:17         0   \n",
       " 9         inc_1_secondary_burner_status  17.02.2018 21:03:17       -20   \n",
       " 10      inc_1_lower_feeding_gate_status  17.02.2018 21:03:17       -10   \n",
       " 11            inc_1_medical_flap_status  17.02.2018 21:03:17        -5   \n",
       " 12          inc_1_primary_burner_status  17.02.2018 21:03:18         0   \n",
       " 13        inc_1_secondary_burner_status  17.02.2018 21:03:18       -20   \n",
       " 14      inc_1_lower_feeding_gate_status  17.02.2018 21:03:18       -10   \n",
       " 15            inc_1_medical_flap_status  17.02.2018 21:03:18        -5   \n",
       " 16          inc_1_primary_burner_status  17.02.2018 21:03:19         0   \n",
       " 17        inc_1_secondary_burner_status  17.02.2018 21:03:19       -20   \n",
       " 18      inc_1_lower_feeding_gate_status  17.02.2018 21:03:19       -10   \n",
       " 19            inc_1_medical_flap_status  17.02.2018 21:03:19        -5   \n",
       " 20          inc_1_primary_burner_status  17.02.2018 21:03:20         0   \n",
       " 21        inc_1_secondary_burner_status  17.02.2018 21:03:20       -20   \n",
       " 22      inc_1_lower_feeding_gate_status  17.02.2018 21:03:20       -10   \n",
       " 23            inc_1_medical_flap_status  17.02.2018 21:03:20        -5   \n",
       " 24          inc_1_primary_burner_status  17.02.2018 21:03:21         0   \n",
       " 25        inc_1_secondary_burner_status  17.02.2018 21:03:21       -20   \n",
       " 26      inc_1_lower_feeding_gate_status  17.02.2018 21:03:21       -10   \n",
       " 27            inc_1_medical_flap_status  17.02.2018 21:03:21        -5   \n",
       " 28          inc_1_primary_burner_status  17.02.2018 21:03:22         0   \n",
       " 29        inc_1_secondary_burner_status  17.02.2018 21:03:22       -20   \n",
       " ...                                 ...                  ...       ...   \n",
       " 499970  inc_1_lower_feeding_gate_status  19.02.2018 08:07:38       -10   \n",
       " 499971        inc_1_medical_flap_status  19.02.2018 08:07:38        -5   \n",
       " 499972      inc_1_primary_burner_status  19.02.2018 08:07:39         0   \n",
       " 499973    inc_1_secondary_burner_status  19.02.2018 08:07:39         0   \n",
       " 499974  inc_1_lower_feeding_gate_status  19.02.2018 08:07:39       -10   \n",
       " 499975        inc_1_medical_flap_status  19.02.2018 08:07:39        -5   \n",
       " 499976      inc_1_primary_burner_status  19.02.2018 08:07:40         0   \n",
       " 499977    inc_1_secondary_burner_status  19.02.2018 08:07:40         0   \n",
       " 499978  inc_1_lower_feeding_gate_status  19.02.2018 08:07:40       -10   \n",
       " 499979        inc_1_medical_flap_status  19.02.2018 08:07:40        -5   \n",
       " 499980      inc_1_primary_burner_status  19.02.2018 08:07:41         0   \n",
       " 499981    inc_1_secondary_burner_status  19.02.2018 08:07:41         0   \n",
       " 499982  inc_1_lower_feeding_gate_status  19.02.2018 08:07:41       -10   \n",
       " 499983        inc_1_medical_flap_status  19.02.2018 08:07:41        -5   \n",
       " 499984      inc_1_primary_burner_status  19.02.2018 08:07:42         0   \n",
       " 499985    inc_1_secondary_burner_status  19.02.2018 08:07:42         0   \n",
       " 499986  inc_1_lower_feeding_gate_status  19.02.2018 08:07:42       -10   \n",
       " 499987        inc_1_medical_flap_status  19.02.2018 08:07:42        -5   \n",
       " 499988      inc_1_primary_burner_status  19.02.2018 08:07:43         0   \n",
       " 499989    inc_1_secondary_burner_status  19.02.2018 08:07:43         0   \n",
       " 499990  inc_1_lower_feeding_gate_status  19.02.2018 08:07:43       -10   \n",
       " 499991        inc_1_medical_flap_status  19.02.2018 08:07:43        -5   \n",
       " 499992      inc_1_primary_burner_status  19.02.2018 08:07:44         0   \n",
       " 499993    inc_1_secondary_burner_status  19.02.2018 08:07:44         0   \n",
       " 499994  inc_1_lower_feeding_gate_status  19.02.2018 08:07:44       -10   \n",
       " 499995        inc_1_medical_flap_status  19.02.2018 08:07:44        -5   \n",
       " 499996      inc_1_primary_burner_status  19.02.2018 08:07:45         0   \n",
       " 499997    inc_1_secondary_burner_status  19.02.2018 08:07:45         0   \n",
       " 499998  inc_1_lower_feeding_gate_status  19.02.2018 08:07:45       -10   \n",
       " 499999        inc_1_medical_flap_status  19.02.2018 08:07:45        -5   \n",
       " \n",
       "         Validity           Time_ms            DateTime  \n",
       " 0              1  43148877259,4097 2018-02-17 21:03:15  \n",
       " 1              1  43148877259,4097 2018-02-17 21:03:15  \n",
       " 2              1  43148877259,4097 2018-02-17 21:03:15  \n",
       " 3              1  43148877259,4097 2018-02-17 21:03:15  \n",
       " 4              1  43148877271,0995 2018-02-17 21:03:16  \n",
       " 5              1  43148877271,0995 2018-02-17 21:03:16  \n",
       " 6              1  43148877271,0995 2018-02-17 21:03:16  \n",
       " 7              1  43148877271,0995 2018-02-17 21:03:16  \n",
       " 8              1  43148877282,8125 2018-02-17 21:03:17  \n",
       " 9              1  43148877282,8125 2018-02-17 21:03:17  \n",
       " 10             1  43148877282,8125 2018-02-17 21:03:17  \n",
       " 11             1  43148877282,8125 2018-02-17 21:03:17  \n",
       " 12             1  43148877294,5023 2018-02-17 21:03:18  \n",
       " 13             1  43148877294,5023 2018-02-17 21:03:18  \n",
       " 14             1  43148877294,5023 2018-02-17 21:03:18  \n",
       " 15             1  43148877294,5023 2018-02-17 21:03:18  \n",
       " 16             1  43148877306,2037 2018-02-17 21:03:19  \n",
       " 17             1  43148877306,2037 2018-02-17 21:03:19  \n",
       " 18             1  43148877306,2037 2018-02-17 21:03:19  \n",
       " 19             1  43148877306,2037 2018-02-17 21:03:19  \n",
       " 20             1  43148877317,8935 2018-02-17 21:03:20  \n",
       " 21             1  43148877317,8935 2018-02-17 21:03:20  \n",
       " 22             1  43148877317,8935 2018-02-17 21:03:20  \n",
       " 23             1  43148877317,8935 2018-02-17 21:03:20  \n",
       " 24             1  43148877329,5833 2018-02-17 21:03:21  \n",
       " 25             1  43148877329,5833 2018-02-17 21:03:21  \n",
       " 26             1  43148877329,5833 2018-02-17 21:03:21  \n",
       " 27             1  43148877329,5833 2018-02-17 21:03:21  \n",
       " 28             1  43148877341,2847 2018-02-17 21:03:22  \n",
       " 29             1  43148877341,2847 2018-02-17 21:03:22  \n",
       " ...          ...               ...                 ...  \n",
       " 499970         1   43150338630,706 2018-02-19 08:07:38  \n",
       " 499971         1   43150338630,706 2018-02-19 08:07:38  \n",
       " 499972         1  43150338642,3958 2018-02-19 08:07:39  \n",
       " 499973         1  43150338642,3958 2018-02-19 08:07:39  \n",
       " 499974         1  43150338642,3958 2018-02-19 08:07:39  \n",
       " 499975         1  43150338642,3958 2018-02-19 08:07:39  \n",
       " 499976         1  43150338654,0857 2018-02-19 08:07:40  \n",
       " 499977         1  43150338654,0857 2018-02-19 08:07:40  \n",
       " 499978         1  43150338654,0857 2018-02-19 08:07:40  \n",
       " 499979         1  43150338654,0857 2018-02-19 08:07:40  \n",
       " 499980         1  43150338665,7755 2018-02-19 08:07:41  \n",
       " 499981         1  43150338665,7755 2018-02-19 08:07:41  \n",
       " 499982         1  43150338665,7755 2018-02-19 08:07:41  \n",
       " 499983         1  43150338665,7755 2018-02-19 08:07:41  \n",
       " 499984         1  43150338677,4653 2018-02-19 08:07:42  \n",
       " 499985         1  43150338677,4653 2018-02-19 08:07:42  \n",
       " 499986         1  43150338677,4653 2018-02-19 08:07:42  \n",
       " 499987         1  43150338677,4653 2018-02-19 08:07:42  \n",
       " 499988         1  43150338689,1667 2018-02-19 08:07:43  \n",
       " 499989         1  43150338689,1667 2018-02-19 08:07:43  \n",
       " 499990         1  43150338689,1667 2018-02-19 08:07:43  \n",
       " 499991         1  43150338689,1667 2018-02-19 08:07:43  \n",
       " 499992         1  43150338700,8565 2018-02-19 08:07:44  \n",
       " 499993         1  43150338700,8565 2018-02-19 08:07:44  \n",
       " 499994         1  43150338700,8565 2018-02-19 08:07:44  \n",
       " 499995         1  43150338700,8565 2018-02-19 08:07:44  \n",
       " 499996         1  43150338712,5463 2018-02-19 08:07:45  \n",
       " 499997         1  43150338712,5463 2018-02-19 08:07:45  \n",
       " 499998         1  43150338712,5463 2018-02-19 08:07:45  \n",
       " 499999         1  43150338712,5463 2018-02-19 08:07:45  \n",
       " \n",
       " [500000 rows x 6 columns], pandas.core.series.Series)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datetime(DWsource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VarName</th>\n",
       "      <th>TimeString</th>\n",
       "      <th>VarValue</th>\n",
       "      <th>Validity</th>\n",
       "      <th>Time_ms</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inc_1_primary_burner_status</td>\n",
       "      <td>17.02.2018 21:03:15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877259,4097</td>\n",
       "      <td>2018-02-17 21:03:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inc_1_secondary_burner_status</td>\n",
       "      <td>17.02.2018 21:03:15</td>\n",
       "      <td>-20</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877259,4097</td>\n",
       "      <td>2018-02-17 21:03:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>17.02.2018 21:03:15</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877259,4097</td>\n",
       "      <td>2018-02-17 21:03:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inc_1_medical_flap_status</td>\n",
       "      <td>17.02.2018 21:03:15</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877259,4097</td>\n",
       "      <td>2018-02-17 21:03:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inc_1_primary_burner_status</td>\n",
       "      <td>17.02.2018 21:03:16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877271,0995</td>\n",
       "      <td>2018-02-17 21:03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>inc_1_secondary_burner_status</td>\n",
       "      <td>17.02.2018 21:03:16</td>\n",
       "      <td>-20</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877271,0995</td>\n",
       "      <td>2018-02-17 21:03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>17.02.2018 21:03:16</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877271,0995</td>\n",
       "      <td>2018-02-17 21:03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inc_1_medical_flap_status</td>\n",
       "      <td>17.02.2018 21:03:16</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877271,0995</td>\n",
       "      <td>2018-02-17 21:03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inc_1_primary_burner_status</td>\n",
       "      <td>17.02.2018 21:03:17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877282,8125</td>\n",
       "      <td>2018-02-17 21:03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>inc_1_secondary_burner_status</td>\n",
       "      <td>17.02.2018 21:03:17</td>\n",
       "      <td>-20</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877282,8125</td>\n",
       "      <td>2018-02-17 21:03:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           VarName           TimeString  VarValue  Validity  \\\n",
       "0      inc_1_primary_burner_status  17.02.2018 21:03:15         0         1   \n",
       "1    inc_1_secondary_burner_status  17.02.2018 21:03:15       -20         1   \n",
       "2  inc_1_lower_feeding_gate_status  17.02.2018 21:03:15       -10         1   \n",
       "3        inc_1_medical_flap_status  17.02.2018 21:03:15        -5         1   \n",
       "4      inc_1_primary_burner_status  17.02.2018 21:03:16         0         1   \n",
       "5    inc_1_secondary_burner_status  17.02.2018 21:03:16       -20         1   \n",
       "6  inc_1_lower_feeding_gate_status  17.02.2018 21:03:16       -10         1   \n",
       "7        inc_1_medical_flap_status  17.02.2018 21:03:16        -5         1   \n",
       "8      inc_1_primary_burner_status  17.02.2018 21:03:17         0         1   \n",
       "9    inc_1_secondary_burner_status  17.02.2018 21:03:17       -20         1   \n",
       "\n",
       "            Time_ms            DateTime  \n",
       "0  43148877259,4097 2018-02-17 21:03:15  \n",
       "1  43148877259,4097 2018-02-17 21:03:15  \n",
       "2  43148877259,4097 2018-02-17 21:03:15  \n",
       "3  43148877259,4097 2018-02-17 21:03:15  \n",
       "4  43148877271,0995 2018-02-17 21:03:16  \n",
       "5  43148877271,0995 2018-02-17 21:03:16  \n",
       "6  43148877271,0995 2018-02-17 21:03:16  \n",
       "7  43148877271,0995 2018-02-17 21:03:16  \n",
       "8  43148877282,8125 2018-02-17 21:03:17  \n",
       "9  43148877282,8125 2018-02-17 21:03:17  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DWsource.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filtvar(df, col):\n",
    "    \"\"\"\n",
    "    Picks up the rows with desired variables\n",
    "\n",
    "    :input: Name of the dataframe and the desired variable in quotes ('').\n",
    "\n",
    "    :return: pandas dataframe with only the desired variable in the VarName-column.\n",
    "    In addition, returns the dimensions of the new filtered DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df[df.VarName == col]\n",
    "    n = df.shape[1]        # second element of \"dimension\" is the number of cols\n",
    "    m = df.shape[0]        # first element of dimension is the number of rows\n",
    "    \n",
    "    print('sample size m=',m)\n",
    "    print('feature length n=',n)\n",
    "\n",
    "    return df, m, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size m= 125000\n",
      "feature length n= 6\n"
     ]
    }
   ],
   "source": [
    "DWtest, m, n, = Filtvar(DWsource, 'inc_1_lower_feeding_gate_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VarName</th>\n",
       "      <th>TimeString</th>\n",
       "      <th>VarValue</th>\n",
       "      <th>Validity</th>\n",
       "      <th>Time_ms</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>17.02.2018 21:03:15</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877259,4097</td>\n",
       "      <td>2018-02-17 21:03:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>17.02.2018 21:03:16</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877271,0995</td>\n",
       "      <td>2018-02-17 21:03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>17.02.2018 21:03:17</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877282,8125</td>\n",
       "      <td>2018-02-17 21:03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>17.02.2018 21:03:18</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877294,5023</td>\n",
       "      <td>2018-02-17 21:03:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>17.02.2018 21:03:19</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43148877306,2037</td>\n",
       "      <td>2018-02-17 21:03:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            VarName           TimeString  VarValue  Validity  \\\n",
       "2   inc_1_lower_feeding_gate_status  17.02.2018 21:03:15       -10         1   \n",
       "6   inc_1_lower_feeding_gate_status  17.02.2018 21:03:16       -10         1   \n",
       "10  inc_1_lower_feeding_gate_status  17.02.2018 21:03:17       -10         1   \n",
       "14  inc_1_lower_feeding_gate_status  17.02.2018 21:03:18       -10         1   \n",
       "18  inc_1_lower_feeding_gate_status  17.02.2018 21:03:19       -10         1   \n",
       "\n",
       "             Time_ms            DateTime  \n",
       "2   43148877259,4097 2018-02-17 21:03:15  \n",
       "6   43148877271,0995 2018-02-17 21:03:16  \n",
       "10  43148877282,8125 2018-02-17 21:03:17  \n",
       "14  43148877294,5023 2018-02-17 21:03:18  \n",
       "18  43148877306,2037 2018-02-17 21:03:19  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DWtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VarName</th>\n",
       "      <th>TimeString</th>\n",
       "      <th>VarValue</th>\n",
       "      <th>Validity</th>\n",
       "      <th>Time_ms</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499982</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>19.02.2018 08:07:41</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43150338665,7755</td>\n",
       "      <td>2018-02-19 08:07:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499986</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>19.02.2018 08:07:42</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43150338677,4653</td>\n",
       "      <td>2018-02-19 08:07:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>19.02.2018 08:07:43</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43150338689,1667</td>\n",
       "      <td>2018-02-19 08:07:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499994</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>19.02.2018 08:07:44</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43150338700,8565</td>\n",
       "      <td>2018-02-19 08:07:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>inc_1_lower_feeding_gate_status</td>\n",
       "      <td>19.02.2018 08:07:45</td>\n",
       "      <td>-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43150338712,5463</td>\n",
       "      <td>2018-02-19 08:07:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                VarName           TimeString  VarValue  \\\n",
       "499982  inc_1_lower_feeding_gate_status  19.02.2018 08:07:41       -10   \n",
       "499986  inc_1_lower_feeding_gate_status  19.02.2018 08:07:42       -10   \n",
       "499990  inc_1_lower_feeding_gate_status  19.02.2018 08:07:43       -10   \n",
       "499994  inc_1_lower_feeding_gate_status  19.02.2018 08:07:44       -10   \n",
       "499998  inc_1_lower_feeding_gate_status  19.02.2018 08:07:45       -10   \n",
       "\n",
       "        Validity           Time_ms            DateTime  \n",
       "499982         1  43150338665,7755 2018-02-19 08:07:41  \n",
       "499986         1  43150338677,4653 2018-02-19 08:07:42  \n",
       "499990         1  43150338689,1667 2018-02-19 08:07:43  \n",
       "499994         1  43150338700,8565 2018-02-19 08:07:44  \n",
       "499998         1  43150338712,5463 2018-02-19 08:07:45  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DWtest.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10    119122\n",
       " 0       5384\n",
       " 10       494\n",
       "Name: VarValue, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DWtest.VarValue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10ca29358>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(DWtest.DateTime, DWtest.VarValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWTank1Level = pd.read_csv('MS6/LEVEL_TANK_A0.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7d53375ef26f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'FW' is not defined"
     ]
    }
   ],
   "source": [
    "FW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWTank2Level = pd.read_csv('MunVene2/LEVEL_TANK_B0.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values for the FW tank \n",
    "\n",
    "- FW tank level as % filling of the full capacity e.g. 47 % \n",
    "- Haarslev FW pump status same as others (20 FWD, 15 BWD, 0 Stop, -5 Fault or overcurrent). 20: pump runs full speed at 60 Hz.\n",
    "- 3-way valve is directing the FW-flow between 2 tanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWTank1Level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWTank2Level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW1id = FWTank1Level.set_index('VarName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW2id = FWTank2Level.set_index('VarName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW1id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW2id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWT1 = FW1id.loc['FOODWASTE_TANK_A_LEVEL_TREND' , 'TimeString' : 'VarValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWT2 = FW2id.loc['FOODWASTE_TANK_B_LEVEL_TREND' , 'TimeString' : 'VarValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWSflow1 = FW1id.loc['HARSLEV_PUMP_1_1PM_1_STATUS', 'TimeString': 'VarValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWSflow2 = FW2id.loc['HARSLEV_PUMP_1_2PM_1_STATUS', 'TimeString': 'VarValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FWT1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWT2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FWT1['runTime'] = pd.date_range(start='2018-02-25 16:07:23', periods=67144, freq='S')\n",
    "FWT1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FWT1['meanLevel'] = FWT1['VarValue'].rolling(12).mean()\n",
    "FWT1['levelDiff'] = FWT1['VarValue'].diff()\n",
    "FWT1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove the discharge from level measurement: Removes negative value < -1 and replaces the the values by zero\n",
    "FWT1.levelDiff.where(FWT1.levelDiff > -2, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(FWT1.TimeString, format = '%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts time string values into datetime value and assigns the serie to new calTime-column\n",
    "FWT1['calTime'] = pd.to_datetime(FWT1.TimeString, format = '%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(FWT1.calTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sum of level increase as percent value\n",
    "FWT1['incrSum'] = FWT1.levelDiff.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sum of level increase as m3\n",
    "FWT1['incrVsum'] = FWT1.incrSum * 5 / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow rate m3/h from 1 h earlier to that moment\n",
    "FWT1['lhFlow'] = FWT1.incrVsum.diff(periods=720)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove the discharge from level measurement: Removes negative value < -1 and replaces the the values by zero\n",
    "FWT1['lmin] = FWT1.lminFlow.where(abs(FWT1.lminFlow) == 50, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWT1.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the volumetric cumulative sum against the time\n",
    "plt.plot(FWT1.calTime, FWT1.incrVsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(FWT1.calTime, FWT1.lhFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWT1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the numbers of status values for the pump. -5 == Fault status\n",
    "FWSflow1.VarValue.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts time string values into datetime value\n",
    "FWSflow1['calTime'] = pd.to_datetime(FWSflow1.TimeString, format = '%d.%m.%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWSflow1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes fault-status (-5)\n",
    "FWSflow1.VarValue.where(FWSflow1.VarValue > 0, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWSflow1.VarValue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for if VarValue == 20 => flowrate = 0.1666 lmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWSflow1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWT2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWT2.any(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWSflow2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = FWT1.loc[:, 'TimeString']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWSflow1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWSflow2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division of the Food Waste flows \n",
    "\n",
    "The produced food waste is separated with a mesh in the tank into:\n",
    "\n",
    "1. Solid food waste (FW)\n",
    "\n",
    "2. Food waste water (FWW)\n",
    "\n",
    "### Food Waste solids (FW)\n",
    "\n",
    "FW is pumped with the Haarslew pump to the screen and further to the drier. As mentioned above, the variable value of 20 tells that the pump is producing with its capacity. The FW flow can be calculated directly from the data as: \n",
    "\n",
    "(flow capacity the pump (e.g. 2 kg / s)) / ( moment of first instance of VarValue 20 and moment of last instance of the VarValue 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food Waste water (FWW)\n",
    "\n",
    "This data describes the flow of load in liquid form out of the waste system.\n",
    "\n",
    "tank water pump \n",
    "\n",
    "- 20 Forward\n",
    "- 15 Backward\n",
    "- 0 Stop\n",
    "- -5 Fault or overcurrent\n",
    "\n",
    "No Hz info presumably 60 Hz\n",
    "\n",
    "The FWW flow can be calculated directly from the data as: \n",
    "\n",
    "(flow capacity the pump (e.g. 20 kg / s)) / ( moment of first instance of VarValue 20 and moment of last instance of the VarValue 20)\n",
    "\n",
    "The carbon can be considered as direct CO2- and nutrient emmision to the environment. All the carbon in the FW water are converted into CO2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWW_flow = pd.read_csv('MunVene2/BORGEN_PUMP0.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWW_flow.head(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FWW_flow.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values for the Biosludge tank:\n",
    "\n",
    "- Biosludge mixing status: 0 = stop, 20 FWD, -5 Fail) \n",
    "- Biosludge tank level: as % filling of the full capacity e.g. 19 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BWTankLevel = pd.read_csv('MunVene2/LEVEL_BIOSLUDGETANK0.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BWTankLevel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BWTankLevel.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values for the Burners:\n",
    "\n",
    "- All temperatures in the main and sec chambers as Celsius degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Burner1 = pd.read_csv('MunVene2/BURNER_10.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Burner1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Burner2 = pd.read_csv('MunVene2/BURNER_20.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Burner2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Burner2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dryer0 = pd.read_csv('MunVene2/DRYER0.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values for the Dryer:\n",
    "\n",
    "- Dryer mixer motor current as %, e.g. 50 %\n",
    "- Dryer temperature as Celcius degrees\n",
    "- Dryer pressure as mbar\n",
    "- Dryer filling weight as kgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dryer0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dryer0.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FluegasTemp0 = pd.read_csv('MunVene2/FLUEGAS0.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values for the Flue gas:\n",
    "\n",
    "- Flue gas temperature as Celcius degrees.\n",
    "- Flue gas fan speed as Hz (or 1/10 Hz). Check!\n",
    "- Flue gas opacity as 0 to 100 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FluegasTemp0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FluegasTemp0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FluegasFlow0 = pd.read_csv('MunVene2/ID_FAN0.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FluegasFlow0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
